{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "from PIL import Image\n",
    "from video_dataset import VideoDataset\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from lip_sync_model.model import BiSeNet\n",
    "from torchvision.ops import masks_to_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiSeNet(\n",
       "  (cp): ContextPath(\n",
       "    (resnet): Resnet18(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (arm16): AttentionRefinementModule(\n",
       "      (conv): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sigmoid_atten): Sigmoid()\n",
       "    )\n",
       "    (arm32): AttentionRefinementModule(\n",
       "      (conv): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sigmoid_atten): Sigmoid()\n",
       "    )\n",
       "    (conv_head32): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_head16): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_avg): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ffm): FeatureFusionModule(\n",
       "    (convblk): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (conv_out): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_out16): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_out32): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lip_model_path = '79999_iter.pth'\n",
    "lip_model = BiSeNet(n_classes=19)\n",
    "lip_model.load_state_dict(torch.load(lip_model_path))\n",
    "lip_model.cuda()\n",
    "lip_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files:  35784\n",
      "Found 28761 videos\n",
      "Skipped 0 videos\n"
     ]
    }
   ],
   "source": [
    "face_ds = VideoDataset(root_dir='dataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    face_ds,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vide_id = \"2r3ddBtpQjA_2\"\n",
    "load_mask = \"dataset/lip_masks/\" + vide_id + \"_mask.pt\"\n",
    "vid_path = \"dataset/train/\" + vide_id + \".mp4\"\n",
    "\n",
    "if os.path.exists(load_mask):\n",
    "    lip_mask = torch.load(load_mask)\n",
    "    video = imageio.get_reader(vid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get bounding box from lip mask and create box mask\n",
    "def get_lip_bbox(lip_mask):\n",
    "    \"\"\"\n",
    "    Extract bounding box coordinates from a lip mask and create a box mask\n",
    "    \n",
    "    Args:\n",
    "        lip_mask: Binary mask tensor with shape (B, N, H, W)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (x_min, y_min, x_max, y_max, box_mask) or None if no lip pixels found\n",
    "              where box_mask is a tensor with ones in the bounding box area\n",
    "    \"\"\"\n",
    "    boxes = masks_to_boxes(lip_mask)\n",
    "   \n",
    "    # Find non-zero coordinates (lip pixels)\n",
    "    y_indices, x_indices = torch.where(lip_mask > 0)\n",
    "       \n",
    "    # Get min and max coordinates to form bounding box\n",
    "    x_min = int(torch.min(x_indices))\n",
    "    y_min = int(torch.min(y_indices))\n",
    "    x_max = int(torch.max(x_indices))\n",
    "    y_max = int(torch.max(y_indices))\n",
    "    \n",
    "    # Create a new mask with ones in the bounding box area\n",
    "    box_mask = torch.zeros_like(lip_mask)\n",
    "    box_mask[y_min:y_max+1, x_min:x_max+1] = 1.0\n",
    "    \n",
    "    return box_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset/train/-2KG4lLGEl0_3.mp4.tensors.pt\n",
    "dataset/train/-2KG4lLGEl0_3.mp4.tensors.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Test the function on our lip mask\n",
    "frame_idx = 10\n",
    "bbox = get_lip_bbox(lip_mask[:frame_idx].unsqueeze(0))\n",
    "\n",
    "frame = video.get_data(frame_idx)\n",
    "frame = Image.fromarray(frame)\n",
    "    \n",
    "# Display original video frame\n",
    "axes[0].imshow(frame)\n",
    "axes[0].set_title('Original Video Frame')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display lip mask, scaling to 255 for better visibility\n",
    "axes[1].imshow(bbox.cpu().numpy() * 255, cmap='gray')\n",
    "axes[1].set_title('Lip Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the output to get the parsing map using torch operations\n",
    "def get_lip_mask(out):\n",
    "    parsing = torch.argmax(out, dim=2)\n",
    "    print(torch.unique(parsing))\n",
    "\n",
    "    # Create a binary mask for lips (class 12 is upper lip, 13 is lower lip)\n",
    "    lip_mask = torch.zeros_like(parsing, dtype=torch.float)\n",
    "    lip_mask[(parsing == 12) | (parsing == 13)] = 1\n",
    "    \n",
    "    return lip_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "video_id = \"YNfuzJwLcT8_2\"\n",
    "vid_path = \"dataset/train/\" + video_id + \".mp4\"\n",
    "video = imageio.get_reader(vid_path)\n",
    "frame = np.array(video.get_data(10)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prep_frame = torch.from_numpy(frame).unsqueeze(0).unsqueeze(0).reshape(1, 1, 3, 512, 512).cuda()\n",
    "\n",
    "    out = lip_model(prep_frame)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = get_lip_mask(out)\n",
    "mask = mask.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = lip_model(torch.stack([face_ds[i][0],face_ds[i+1][0],face_ds[i+2][0]]).to('cuda'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_parsing_maps(im, parsing_anno, stride, save_im=False, save_path='vis_results/parsing_map_on_im.jpg'):\n",
    "    # Colors for all 20 parts\n",
    "    part_colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0],\n",
    "                   [255, 0, 85], [255, 0, 170],\n",
    "                   [0, 255, 0], [85, 255, 0], [170, 255, 0],\n",
    "                   [0, 255, 85], [0, 255, 170],\n",
    "                   [0, 0, 255], [85, 0, 255], [170, 0, 255],\n",
    "                   [0, 85, 255], [0, 170, 255],\n",
    "                   [255, 255, 0], [255, 255, 85], [255, 255, 170],\n",
    "                   [255, 0, 255], [255, 85, 255], [255, 170, 255],\n",
    "                   [0, 255, 255], [85, 255, 255], [170, 255, 255]]\n",
    "\n",
    "    im = np.array(im)\n",
    "    vis_im = im.copy().astype(np.uint8)\n",
    "    vis_parsing_anno = parsing_anno.copy().astype(np.uint8)\n",
    "    vis_parsing_anno = cv2.resize(vis_parsing_anno, None, fx=stride, fy=stride, interpolation=cv2.INTER_NEAREST)\n",
    "    vis_parsing_anno_color = np.zeros((vis_parsing_anno.shape[0], vis_parsing_anno.shape[1], 3)) + 255\n",
    "\n",
    "    num_of_class = np.max(vis_parsing_anno)\n",
    "\n",
    "    for pi in range(1, num_of_class + 1):\n",
    "        index = np.where(vis_parsing_anno == pi)\n",
    "        vis_parsing_anno_color[index[0], index[1], :] = part_colors[pi]\n",
    "\n",
    "    vis_parsing_anno_color = vis_parsing_anno_color.astype(np.uint8)\n",
    "    # print(vis_parsing_anno_color.shape, vis_im.shape)\n",
    "    vis_im = cv2.addWeighted(cv2.cvtColor(vis_im, cv2.COLOR_RGB2BGR), 0.4, vis_parsing_anno_color, 0.6, 0)\n",
    "\n",
    "    # Save result or not\n",
    "    if save_im:\n",
    "        cv2.imwrite(save_path[:-4] +'.png', vis_parsing_anno)\n",
    "        cv2.imwrite(save_path, vis_im, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "\n",
    "    # return vis_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view lip mask and original video side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "video_idx = 1\n",
    "frame_idx = 50\n",
    "# Display original video frame\n",
    "axes[0].imshow(face_ds[video_idx][0][frame_idx].permute(1, 2, 0).cpu().numpy())\n",
    "axes[0].set_title('Original Video Frame')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display lip mask, scaling to 255 for better visibility\n",
    "axes[1].imshow(lip_mask[video_idx][frame_idx].cpu().numpy() * 255, cmap='gray')\n",
    "axes[1].set_title('Lip Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_mask_tensor = lip_mask[0].to(torch.uint8)  # uint8 is the smallest int format for binary mask\n",
    "torch.save(lip_mask_tensor, 'lip_mask.pt')\n",
    "print(f\"Lip mask tensor saved with shape: {lip_mask_tensor.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
