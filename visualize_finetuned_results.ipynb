{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabieririzar/DiffSynth-Studio/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffsynth import ModelManager, WanVideoPipeline, save_video, VideoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = \"models/lip_finetuned/wandb/diffsynth-studio/mofue195/checkpoints/model-step=350.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager = ModelManager(torch_dtype=torch.bfloat16, device=\"cpu\")\n",
    "model_manager.load_models([\n",
    "    \"models/Wan-AI/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors\",\n",
    "    \"models/Wan-AI/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\",\n",
    "    \"models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\",\n",
    "])\n",
    "model_manager.load_lora(trained_model_path, lora_alpha=1.0)\n",
    "pipe = WanVideoPipeline.from_model_manager(model_manager, device=\"cuda\")\n",
    "pipe.enable_vram_management(num_persistent_param_in_dit=None)\n",
    "\n",
    "video = pipe(\n",
    "    prompt=\"i was telling my friend about how much i wanted to see him\",\n",
    "    negative_prompt=\"low quality, unclear facial expressions, blurry\",\n",
    "    num_inference_steps=50,\n",
    "    seed=0, tiled=True\n",
    ")\n",
    "save_video(video, \"video.mp4\", fps=30, quality=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FPFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: models/Wan-AI/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors\n",
      "    model_name: wan_video_dit model_class: WanModel\n",
      "        This model is initialized with extra kwargs: {'has_image_input': False, 'patch_size': [1, 2, 2], 'in_dim': 16, 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'text_dim': 4096, 'out_dim': 16, 'num_heads': 12, 'num_layers': 30, 'eps': 1e-06}\n",
      "    The following models are loaded: ['wan_video_dit'].\n",
      "Loading models from: models/Wan-AI/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "    model_name: wan_video_text_encoder model_class: WanTextEncoder\n",
      "    The following models are loaded: ['wan_video_text_encoder'].\n",
      "Loading models from: models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\n",
      "    model_name: wan_video_vae model_class: WanVideoVAE\n",
      "    The following models are loaded: ['wan_video_vae'].\n",
      "Using wan_video_text_encoder from models/Wan-AI/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth.\n",
      "Using wan_video_dit from models/Wan-AI/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors.\n",
      "Using wan_video_vae from models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth.\n",
      "No wan_video_image_encoder models available.\n",
      "No wan_video_motion_controller models available.\n",
      "No wan_video_vace models available.\n",
      "Prompt:  A person clearly saying 'What is it that you've been doing all of this time?' with synchronized lip movements, clear articulation, mouth movements matching each syllable, precise lip sync\n",
      "Prompt:  low quality, unclear facial expressions, blurry, misaligned audio, poor lip synchronization, static mouth, mumbling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:26<00:00,  1.74s/it]\n",
      "VAE decoding: 100%|██████████| 9/9 [00:04<00:00,  1.96it/s]\n",
      "Saving video:   0%|          | 0/81 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving video: 100%|██████████| 81/81 [00:00<00:00, 417.89it/s]\n"
     ]
    }
   ],
   "source": [
    "model_manager = ModelManager(torch_dtype=torch.bfloat16, device=\"cpu\")\n",
    "model_manager.load_models([\n",
    "    \"models/Wan-AI/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors\",\n",
    "    \"models/Wan-AI/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\",\n",
    "    \"models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\",\n",
    "])\n",
    "pipe = WanVideoPipeline.from_model_manager(model_manager, device=\"cuda\")\n",
    "pipe.enable_vram_management(num_persistent_param_in_dit=None)\n",
    "\n",
    "video = pipe(\n",
    "    prompt=\"A person clearly saying 'What is it that you've been doing all of this time?' with synchronized lip movements, clear articulation, mouth movements matching each syllable, precise lip sync\",\n",
    "    negative_prompt=\"low quality, unclear facial expressions, blurry, misaligned audio, poor lip synchronization, static mouth, mumbling\",\n",
    "    num_inference_steps=50,\n",
    "    seed=0, tiled=True\n",
    ")\n",
    "save_video(video, \"video.mp4\", fps=20, quality=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
