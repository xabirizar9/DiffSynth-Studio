{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"dataset/\")\n",
    "metadata = pd.read_csv(base_dir / \"metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = [base_dir / \"lip_masks/\" / filename.replace(\".mp4\", \"_mask.pt\") for filename in metadata[\"file_name\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for minimum number of non-zero elements\n",
    "threshold = 100  # Adjust this threshold as needed\n",
    "\n",
    "# Lists to store paths and statistics\n",
    "valid_paths = []\n",
    "discard_paths = []\n",
    "non_zero_counts = []\n",
    "total_frames = []\n",
    "non_zero_ratios = []\n",
    "frame_counts = []  # To track the number of frames in each tensor\n",
    "\n",
    "# Use multiprocessing to speed up processing\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "def process_tensor(tensor_path, threshold):\n",
    "    try:\n",
    "        # Use torch.load with map_location to control memory usage\n",
    "        tensor = torch.load(str(tensor_path), map_location='cpu')\n",
    "        \n",
    "        # Check if the tensor has exactly 15 frames\n",
    "        frame_count = tensor.shape[0] if len(tensor.shape) > 0 else 0\n",
    "        has_correct_frames = frame_count == 15\n",
    "        \n",
    "        # Get the count of non-zero elements\n",
    "        non_zero_count = torch.count_nonzero(tensor).item()\n",
    "        \n",
    "        # Get total number of elements in the tensor\n",
    "        total_frame_count = tensor.numel()\n",
    "        \n",
    "        # Calculate ratio of non-zero elements\n",
    "        ratio = non_zero_count / total_frame_count if total_frame_count > 0 else 0\n",
    "        \n",
    "        # Check if count is below threshold and has correct frame count\n",
    "        is_valid = non_zero_count >= threshold and has_correct_frames\n",
    "        \n",
    "        # Free memory\n",
    "        del tensor\n",
    "        \n",
    "        return {\n",
    "            'path': tensor_path,\n",
    "            'is_valid': is_valid,\n",
    "            'non_zero_count': non_zero_count,\n",
    "            'total_frame_count': total_frame_count,\n",
    "            'ratio': ratio,\n",
    "            'frame_count': frame_count\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {tensor_path}: {e}\")\n",
    "        return {\n",
    "            'path': tensor_path,\n",
    "            'is_valid': False,\n",
    "            'non_zero_count': 0,\n",
    "            'total_frame_count': 0,\n",
    "            'ratio': 0,\n",
    "            'frame_count': 0\n",
    "        }\n",
    "\n",
    "# Print progress\n",
    "print(f\"Processing {len(mask_paths)} mask files with {mp.cpu_count()} CPU cores...\")\n",
    "\n",
    "# Create a pool of workers\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    # Process tensors in parallel with progress tracking\n",
    "    results = []\n",
    "    for i, result in enumerate(pool.imap(partial(process_tensor, threshold=threshold), mask_paths)):\n",
    "        results.append(result)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Processing {i} out of {len(mask_paths)}\")\n",
    "\n",
    "# Organize results\n",
    "for result in results:\n",
    "    if result['is_valid']:\n",
    "        valid_paths.append(result['path'])\n",
    "    else:\n",
    "        discard_paths.append(result['path'])\n",
    "    \n",
    "    non_zero_counts.append(result['non_zero_count'])\n",
    "    total_frames.append(result['total_frame_count'])\n",
    "    non_zero_ratios.append(result['ratio'])\n",
    "    frame_counts.append(result['frame_count'])\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total mask files: {len(mask_paths)}\")\n",
    "print(f\"Valid mask files: {len(valid_paths)}\")\n",
    "print(f\"Discarded mask files: {len(discard_paths)}\")\n",
    "print(f\"Average non-zero elements: {np.mean(non_zero_counts):.2f}\")\n",
    "print(f\"Median non-zero elements: {np.median(non_zero_counts):.2f}\")\n",
    "print(f\"Min non-zero elements: {min(non_zero_counts) if non_zero_counts else 0}\")\n",
    "print(f\"Max non-zero elements: {max(non_zero_counts) if non_zero_counts else 0}\")\n",
    "print(f\"Average non-zero ratio: {np.mean(non_zero_ratios):.4f}\")\n",
    "print(f\"Frame count distribution: {pd.Series(frame_counts).value_counts().sort_index().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_df = pd.DataFrame({\"file_name\": [path.name.replace(\"_mask.pt\", \".mp4\") for path in discard_paths]})\n",
    "discard_df.to_csv(base_dir /\"discard_masks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter original metadata.csv to remove discard_df\n",
    "metadata_filtered = metadata[~metadata[\"file_name\"].isin(discard_df[\"file_name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filtered.to_csv(base_dir / \"filtered_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video using a video reader instead of imread\n",
    "import cv2\n",
    "video_path = str(base_dir / \"train\" / discard_df[\"file_name\"][40].replace(\"_mask.pt\", \".mp4\"))\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, first_frame = cap.read()\n",
    "if ret:\n",
    "    # Convert BGR to RGB\n",
    "    first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "else:\n",
    "    print(f\"Failed to read video: {video_path}\")\n",
    "    first_frame = np.zeros((256, 256, 3), dtype=np.uint8)  # Placeholder\n",
    "cap.release()\n",
    "\n",
    "# Load the mask\n",
    "mask_path = str(base_dir / \"lip_masks\" / discard_df[\"file_name\"][100])\n",
    "load_mask = torch.load(mask_path).cpu().numpy().squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize discarded mask and original image side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "\n",
    "\n",
    "axes[0].imshow(first_frame)\n",
    "axes[1].imshow(load_mask)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tensor_path in mask_paths:\n",
    "    tensors = torch.load(tensor_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
